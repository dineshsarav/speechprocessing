{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8bdc46c",
   "metadata": {},
   "source": [
    "### BL.EN.U4AIE21099\n",
    "### Perumalla Dinesh Saravan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfe5bb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98ddcbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67fda210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student</th>\n",
       "      <th>Report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1</td>\n",
       "      <td>So based on the data, the first point what can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S2</td>\n",
       "      <td>I would suggest to make an application in whic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S3</td>\n",
       "      <td>so what i observed is features in irctc data a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S4</td>\n",
       "      <td>This can be solved with a Regression Machine L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S5</td>\n",
       "      <td>From the stock data provided to build a system...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>S6</td>\n",
       "      <td>IRCTC Stock Price \\nSo what i found is functio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S7</td>\n",
       "      <td>The loss probability is showing close to 50 , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S8</td>\n",
       "      <td>1.In the first problem we were able to find ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S9</td>\n",
       "      <td>okay so basically using numpy,we could solve t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S10</td>\n",
       "      <td>Machine learning enables us to build a system ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>S11</td>\n",
       "      <td>From the stock,I see that almost all the value...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>S12</td>\n",
       "      <td>The loss probability is showing close to 50 , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>S13</td>\n",
       "      <td>After observing the daily trend of change perc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>S14</td>\n",
       "      <td>Machine learning helps us to build a system th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>S15</td>\n",
       "      <td>I have observed that, the values are closely r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>S16</td>\n",
       "      <td>To build a system that is capable of predictin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>S17</td>\n",
       "      <td>We are given Price and Change  for every month...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>S18</td>\n",
       "      <td>Usually its difficult to predict stock prices ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>S19</td>\n",
       "      <td>sry sir, i dont know how to suggest a sytem or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>S20</td>\n",
       "      <td>\\nSuggestions to build a system that may be ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>S21</td>\n",
       "      <td>After Analysing, irctc stocks I thought it’s b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>S22</td>\n",
       "      <td>we can apply REGRESSION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>S23</td>\n",
       "      <td>So for that first I imported the dataset and t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>S24</td>\n",
       "      <td>So for that first I imported the dataset and t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>S25</td>\n",
       "      <td>From the stock I see that almost all the value...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>S26</td>\n",
       "      <td>i observed that the features in irctc data ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>S27</td>\n",
       "      <td>A1  \\nI have solved the problems and I found t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>S28</td>\n",
       "      <td>“IRCTC Stock Price  \\n\\nso what i observed is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>S29</td>\n",
       "      <td>IRCTC Stock Price \\nSo what i found is functio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>S30</td>\n",
       "      <td>From the stock data set, I realized that most ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>S31</td>\n",
       "      <td>The loss probability is showing close to 50 , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>S32</td>\n",
       "      <td>From the above information I understand that v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>S33</td>\n",
       "      <td>From the stock I see that almost all the valu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>S34</td>\n",
       "      <td>IRCTC Stock Price \\nso, what I observed is fea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>S35</td>\n",
       "      <td>The loss probability is showing close to 50 , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>S36</td>\n",
       "      <td>we can apply REGRESSION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>S37</td>\n",
       "      <td>“IRCTC Stock Price  \\nso what i observed is fe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Student                                             Report\n",
       "0       S1  So based on the data, the first point what can...\n",
       "1       S2  I would suggest to make an application in whic...\n",
       "2       S3  so what i observed is features in irctc data a...\n",
       "3       S4  This can be solved with a Regression Machine L...\n",
       "4       S5  From the stock data provided to build a system...\n",
       "5       S6  IRCTC Stock Price \\nSo what i found is functio...\n",
       "6       S7  The loss probability is showing close to 50 , ...\n",
       "7       S8  1.In the first problem we were able to find ou...\n",
       "8       S9  okay so basically using numpy,we could solve t...\n",
       "9      S10  Machine learning enables us to build a system ...\n",
       "10     S11  From the stock,I see that almost all the value...\n",
       "11     S12  The loss probability is showing close to 50 , ...\n",
       "12     S13  After observing the daily trend of change perc...\n",
       "13     S14  Machine learning helps us to build a system th...\n",
       "14     S15  I have observed that, the values are closely r...\n",
       "15     S16  To build a system that is capable of predictin...\n",
       "16     S17  We are given Price and Change  for every month...\n",
       "17     S18  Usually its difficult to predict stock prices ...\n",
       "18     S19  sry sir, i dont know how to suggest a sytem or...\n",
       "19     S20  \\nSuggestions to build a system that may be ab...\n",
       "20     S21  After Analysing, irctc stocks I thought it’s b...\n",
       "21     S22                            we can apply REGRESSION\n",
       "22     S23  So for that first I imported the dataset and t...\n",
       "23     S24  So for that first I imported the dataset and t...\n",
       "24     S25  From the stock I see that almost all the value...\n",
       "25     S26   i observed that the features in irctc data ar...\n",
       "26     S27  A1  \\nI have solved the problems and I found t...\n",
       "27     S28  “IRCTC Stock Price  \\n\\nso what i observed is ...\n",
       "28     S29  IRCTC Stock Price \\nSo what i found is functio...\n",
       "29     S30  From the stock data set, I realized that most ...\n",
       "30     S31  The loss probability is showing close to 50 , ...\n",
       "31     S32  From the above information I understand that v...\n",
       "32     S33   From the stock I see that almost all the valu...\n",
       "33     S34  IRCTC Stock Price \\nso, what I observed is fea...\n",
       "34     S35  The loss probability is showing close to 50 , ...\n",
       "35     S36                            we can apply REGRESSION\n",
       "36     S37  “IRCTC Stock Price  \\nso what i observed is fe..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"Lab-Session2-Data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1e08bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student</th>\n",
       "      <th>Report</th>\n",
       "      <th>tokenized_column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1</td>\n",
       "      <td>So based on the data, the first point what can...</td>\n",
       "      <td>[So, based, on, the, data, ,, the, first, poin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S2</td>\n",
       "      <td>I would suggest to make an application in whic...</td>\n",
       "      <td>[I, would, suggest, to, make, an, application,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S3</td>\n",
       "      <td>so what i observed is features in irctc data a...</td>\n",
       "      <td>[so, what, i, observed, is, features, in, irct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S4</td>\n",
       "      <td>This can be solved with a Regression Machine L...</td>\n",
       "      <td>[This, can, be, solved, with, a, Regression, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S5</td>\n",
       "      <td>From the stock data provided to build a system...</td>\n",
       "      <td>[From, the, stock, data, provided, to, build, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>S6</td>\n",
       "      <td>IRCTC Stock Price \\nSo what i found is functio...</td>\n",
       "      <td>[IRCTC, Stock, Price, So, what, i, found, is, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S7</td>\n",
       "      <td>The loss probability is showing close to 50 , ...</td>\n",
       "      <td>[The, loss, probability, is, showing, close, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S8</td>\n",
       "      <td>1.In the first problem we were able to find ou...</td>\n",
       "      <td>[1.In, the, first, problem, we, were, able, to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S9</td>\n",
       "      <td>okay so basically using numpy,we could solve t...</td>\n",
       "      <td>[okay, so, basically, using, numpy, ,, we, cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S10</td>\n",
       "      <td>Machine learning enables us to build a system ...</td>\n",
       "      <td>[Machine, learning, enables, us, to, build, a,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>S11</td>\n",
       "      <td>From the stock,I see that almost all the value...</td>\n",
       "      <td>[From, the, stock, ,, I, see, that, almost, al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>S12</td>\n",
       "      <td>The loss probability is showing close to 50 , ...</td>\n",
       "      <td>[The, loss, probability, is, showing, close, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>S13</td>\n",
       "      <td>After observing the daily trend of change perc...</td>\n",
       "      <td>[After, observing, the, daily, trend, of, chan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>S14</td>\n",
       "      <td>Machine learning helps us to build a system th...</td>\n",
       "      <td>[Machine, learning, helps, us, to, build, a, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>S15</td>\n",
       "      <td>I have observed that, the values are closely r...</td>\n",
       "      <td>[I, have, observed, that, ,, the, values, are,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>S16</td>\n",
       "      <td>To build a system that is capable of predictin...</td>\n",
       "      <td>[To, build, a, system, that, is, capable, of, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>S17</td>\n",
       "      <td>We are given Price and Change  for every month...</td>\n",
       "      <td>[We, are, given, Price, and, Change, for, ever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>S18</td>\n",
       "      <td>Usually its difficult to predict stock prices ...</td>\n",
       "      <td>[Usually, its, difficult, to, predict, stock, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>S19</td>\n",
       "      <td>sry sir, i dont know how to suggest a sytem or...</td>\n",
       "      <td>[sry, sir, ,, i, dont, know, how, to, suggest,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>S20</td>\n",
       "      <td>\\nSuggestions to build a system that may be ab...</td>\n",
       "      <td>[Suggestions, to, build, a, system, that, may,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>S21</td>\n",
       "      <td>After Analysing, irctc stocks I thought it’s b...</td>\n",
       "      <td>[After, Analysing, ,, irctc, stocks, I, though...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>S22</td>\n",
       "      <td>we can apply REGRESSION</td>\n",
       "      <td>[we, can, apply, REGRESSION]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>S23</td>\n",
       "      <td>So for that first I imported the dataset and t...</td>\n",
       "      <td>[So, for, that, first, I, imported, the, datas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>S24</td>\n",
       "      <td>So for that first I imported the dataset and t...</td>\n",
       "      <td>[So, for, that, first, I, imported, the, datas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>S25</td>\n",
       "      <td>From the stock I see that almost all the value...</td>\n",
       "      <td>[From, the, stock, I, see, that, almost, all, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>S26</td>\n",
       "      <td>i observed that the features in irctc data ar...</td>\n",
       "      <td>[i, observed, that, the, features, in, irctc, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>S27</td>\n",
       "      <td>A1  \\nI have solved the problems and I found t...</td>\n",
       "      <td>[A1, I, have, solved, the, problems, and, I, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>S28</td>\n",
       "      <td>“IRCTC Stock Price  \\n\\nso what i observed is ...</td>\n",
       "      <td>[“, IRCTC, Stock, Price, so, what, i, observed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>S29</td>\n",
       "      <td>IRCTC Stock Price \\nSo what i found is functio...</td>\n",
       "      <td>[IRCTC, Stock, Price, So, what, i, found, is, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>S30</td>\n",
       "      <td>From the stock data set, I realized that most ...</td>\n",
       "      <td>[From, the, stock, data, set, ,, I, realized, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>S31</td>\n",
       "      <td>The loss probability is showing close to 50 , ...</td>\n",
       "      <td>[The, loss, probability, is, showing, close, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>S32</td>\n",
       "      <td>From the above information I understand that v...</td>\n",
       "      <td>[From, the, above, information, I, understand,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>S33</td>\n",
       "      <td>From the stock I see that almost all the valu...</td>\n",
       "      <td>[From, the, stock, I, see, that, almost, all, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>S34</td>\n",
       "      <td>IRCTC Stock Price \\nso, what I observed is fea...</td>\n",
       "      <td>[IRCTC, Stock, Price, so, ,, what, I, observed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>S35</td>\n",
       "      <td>The loss probability is showing close to 50 , ...</td>\n",
       "      <td>[The, loss, probability, is, showing, close, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>S36</td>\n",
       "      <td>we can apply REGRESSION</td>\n",
       "      <td>[we, can, apply, REGRESSION]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>S37</td>\n",
       "      <td>“IRCTC Stock Price  \\nso what i observed is fe...</td>\n",
       "      <td>[“, IRCTC, Stock, Price, so, what, i, observed...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Student                                             Report  \\\n",
       "0       S1  So based on the data, the first point what can...   \n",
       "1       S2  I would suggest to make an application in whic...   \n",
       "2       S3  so what i observed is features in irctc data a...   \n",
       "3       S4  This can be solved with a Regression Machine L...   \n",
       "4       S5  From the stock data provided to build a system...   \n",
       "5       S6  IRCTC Stock Price \\nSo what i found is functio...   \n",
       "6       S7  The loss probability is showing close to 50 , ...   \n",
       "7       S8  1.In the first problem we were able to find ou...   \n",
       "8       S9  okay so basically using numpy,we could solve t...   \n",
       "9      S10  Machine learning enables us to build a system ...   \n",
       "10     S11  From the stock,I see that almost all the value...   \n",
       "11     S12  The loss probability is showing close to 50 , ...   \n",
       "12     S13  After observing the daily trend of change perc...   \n",
       "13     S14  Machine learning helps us to build a system th...   \n",
       "14     S15  I have observed that, the values are closely r...   \n",
       "15     S16  To build a system that is capable of predictin...   \n",
       "16     S17  We are given Price and Change  for every month...   \n",
       "17     S18  Usually its difficult to predict stock prices ...   \n",
       "18     S19  sry sir, i dont know how to suggest a sytem or...   \n",
       "19     S20  \\nSuggestions to build a system that may be ab...   \n",
       "20     S21  After Analysing, irctc stocks I thought it’s b...   \n",
       "21     S22                            we can apply REGRESSION   \n",
       "22     S23  So for that first I imported the dataset and t...   \n",
       "23     S24  So for that first I imported the dataset and t...   \n",
       "24     S25  From the stock I see that almost all the value...   \n",
       "25     S26   i observed that the features in irctc data ar...   \n",
       "26     S27  A1  \\nI have solved the problems and I found t...   \n",
       "27     S28  “IRCTC Stock Price  \\n\\nso what i observed is ...   \n",
       "28     S29  IRCTC Stock Price \\nSo what i found is functio...   \n",
       "29     S30  From the stock data set, I realized that most ...   \n",
       "30     S31  The loss probability is showing close to 50 , ...   \n",
       "31     S32  From the above information I understand that v...   \n",
       "32     S33   From the stock I see that almost all the valu...   \n",
       "33     S34  IRCTC Stock Price \\nso, what I observed is fea...   \n",
       "34     S35  The loss probability is showing close to 50 , ...   \n",
       "35     S36                            we can apply REGRESSION   \n",
       "36     S37  “IRCTC Stock Price  \\nso what i observed is fe...   \n",
       "\n",
       "                                     tokenized_column  \n",
       "0   [So, based, on, the, data, ,, the, first, poin...  \n",
       "1   [I, would, suggest, to, make, an, application,...  \n",
       "2   [so, what, i, observed, is, features, in, irct...  \n",
       "3   [This, can, be, solved, with, a, Regression, M...  \n",
       "4   [From, the, stock, data, provided, to, build, ...  \n",
       "5   [IRCTC, Stock, Price, So, what, i, found, is, ...  \n",
       "6   [The, loss, probability, is, showing, close, t...  \n",
       "7   [1.In, the, first, problem, we, were, able, to...  \n",
       "8   [okay, so, basically, using, numpy, ,, we, cou...  \n",
       "9   [Machine, learning, enables, us, to, build, a,...  \n",
       "10  [From, the, stock, ,, I, see, that, almost, al...  \n",
       "11  [The, loss, probability, is, showing, close, t...  \n",
       "12  [After, observing, the, daily, trend, of, chan...  \n",
       "13  [Machine, learning, helps, us, to, build, a, s...  \n",
       "14  [I, have, observed, that, ,, the, values, are,...  \n",
       "15  [To, build, a, system, that, is, capable, of, ...  \n",
       "16  [We, are, given, Price, and, Change, for, ever...  \n",
       "17  [Usually, its, difficult, to, predict, stock, ...  \n",
       "18  [sry, sir, ,, i, dont, know, how, to, suggest,...  \n",
       "19  [Suggestions, to, build, a, system, that, may,...  \n",
       "20  [After, Analysing, ,, irctc, stocks, I, though...  \n",
       "21                       [we, can, apply, REGRESSION]  \n",
       "22  [So, for, that, first, I, imported, the, datas...  \n",
       "23  [So, for, that, first, I, imported, the, datas...  \n",
       "24  [From, the, stock, I, see, that, almost, all, ...  \n",
       "25  [i, observed, that, the, features, in, irctc, ...  \n",
       "26  [A1, I, have, solved, the, problems, and, I, f...  \n",
       "27  [“, IRCTC, Stock, Price, so, what, i, observed...  \n",
       "28  [IRCTC, Stock, Price, So, what, i, found, is, ...  \n",
       "29  [From, the, stock, data, set, ,, I, realized, ...  \n",
       "30  [The, loss, probability, is, showing, close, t...  \n",
       "31  [From, the, above, information, I, understand,...  \n",
       "32  [From, the, stock, I, see, that, almost, all, ...  \n",
       "33  [IRCTC, Stock, Price, so, ,, what, I, observed...  \n",
       "34  [The, loss, probability, is, showing, close, t...  \n",
       "35                       [we, can, apply, REGRESSION]  \n",
       "36  [“, IRCTC, Stock, Price, so, what, i, observed...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "df['tokenized_column'] = df['Report'].apply(lambda x: word_tokenize(str(x)))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f69a84",
   "metadata": {},
   "source": [
    "#A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b3d5117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'certain',\n",
       " 'at',\n",
       " 'took',\n",
       " 'From',\n",
       " 'blunders',\n",
       " ',',\n",
       " 'selected',\n",
       " 'say',\n",
       " 'dataset',\n",
       " 'sense',\n",
       " 'IRCTC',\n",
       " 'in',\n",
       " 'forecasting',\n",
       " 'close',\n",
       " 'difficult',\n",
       " 'Learning',\n",
       " 'he',\n",
       " 'features',\n",
       " 'split',\n",
       " 'observed',\n",
       " 'predictions.anyways',\n",
       " 'is',\n",
       " 'dont',\n",
       " 'closer',\n",
       " 'output',\n",
       " '16',\n",
       " 'REGRESSION',\n",
       " 'set',\n",
       " 'i',\n",
       " 'variance.We',\n",
       " 'it',\n",
       " ')',\n",
       " 'Stock',\n",
       " 'however',\n",
       " 'try',\n",
       " 'Tuesday',\n",
       " 'NAN',\n",
       " 'see',\n",
       " 'extraordinarily',\n",
       " 'sample',\n",
       " 'specific',\n",
       " 'useful',\n",
       " 'mean',\n",
       " 'showing',\n",
       " 'prediction',\n",
       " 'simple',\n",
       " 'This',\n",
       " 'base',\n",
       " 'problems',\n",
       " \"'ve\",\n",
       " 'inputs',\n",
       " 'By',\n",
       " 'prices',\n",
       " 'understanding',\n",
       " 'one',\n",
       " 'could',\n",
       " 'python',\n",
       " '1560.6634',\n",
       " '1.In',\n",
       " 'unknown',\n",
       " 'make',\n",
       " 'basically',\n",
       " 'fashions',\n",
       " 'positively',\n",
       " 'good',\n",
       " 'first',\n",
       " 'whereas',\n",
       " 'based',\n",
       " 'rate',\n",
       " 'amount',\n",
       " 'In',\n",
       " '1550.7060.',\n",
       " 'range',\n",
       " 'years',\n",
       " 'pretty',\n",
       " 'their',\n",
       " '2081.85/-',\n",
       " 'given',\n",
       " 'With',\n",
       " 'Prices',\n",
       " '’',\n",
       " 'histograms',\n",
       " 'timegap',\n",
       " 'doing',\n",
       " 'on',\n",
       " 'variables',\n",
       " 'having',\n",
       " 'functions',\n",
       " 'developing',\n",
       " 'also',\n",
       " 'month',\n",
       " 'multiple',\n",
       " 'near',\n",
       " 'we',\n",
       " 'inverse',\n",
       " 'build',\n",
       " 'Its',\n",
       " 'regression',\n",
       " 'mathematical',\n",
       " 'Lstm',\n",
       " 'problem',\n",
       " 'Lable',\n",
       " 'conditions',\n",
       " 'irctc',\n",
       " 'past',\n",
       " 'current',\n",
       " 'both',\n",
       " 'knowing',\n",
       " 'were',\n",
       " 'wants',\n",
       " 'error',\n",
       " 'okay',\n",
       " '0.ninety',\n",
       " 'implementing',\n",
       " 'outliers',\n",
       " 'y',\n",
       " 'small',\n",
       " 'lot',\n",
       " 'closely',\n",
       " 'widely',\n",
       " 'been',\n",
       " 'describes',\n",
       " 'conclude',\n",
       " 'about',\n",
       " 'without',\n",
       " 'might',\n",
       " 'Nineteen',\n",
       " 'experience',\n",
       " 'outlier',\n",
       " 'Pandas',\n",
       " 'year',\n",
       " 'idea',\n",
       " 'ML',\n",
       " 'A1',\n",
       " 'few',\n",
       " 'outputs',\n",
       " '.',\n",
       " 'If',\n",
       " '..',\n",
       " 'A',\n",
       " '0.98',\n",
       " 'price',\n",
       " 'Since',\n",
       " 'fit',\n",
       " 'Y_train',\n",
       " 'stock',\n",
       " 'precise',\n",
       " 'Machine',\n",
       " 'psuedo',\n",
       " 'low',\n",
       " '.This',\n",
       " 'shows',\n",
       " 'sry',\n",
       " 'wednesday',\n",
       " 'where',\n",
       " 'after',\n",
       " 'so',\n",
       " 'must',\n",
       " 'observation',\n",
       " 'sections',\n",
       " 'product',\n",
       " '“',\n",
       " 'sytem',\n",
       " 'rank',\n",
       " '124',\n",
       " 'using',\n",
       " 'profits',\n",
       " 'day',\n",
       " 'decrease',\n",
       " 'pricing.It',\n",
       " 'methods',\n",
       " 'inferred',\n",
       " 'For',\n",
       " 'trend',\n",
       " 'arrived',\n",
       " 'Regression',\n",
       " 'know',\n",
       " 'according',\n",
       " 'X_train',\n",
       " 'solved',\n",
       " 'application',\n",
       " 'prize',\n",
       " 'Time',\n",
       " 'removing',\n",
       " 'values',\n",
       " 'or',\n",
       " 'can',\n",
       " 'Analysing',\n",
       " 'comparisons',\n",
       " 'unit',\n",
       " 'what',\n",
       " 'Also',\n",
       " 'us',\n",
       " 'data.this',\n",
       " 'compare',\n",
       " 'size',\n",
       " 'maybe',\n",
       " 'min',\n",
       " 'realized',\n",
       " 'expected',\n",
       " 'equation',\n",
       " 'factors',\n",
       " 'larger',\n",
       " 'all',\n",
       " 'only',\n",
       " 'X',\n",
       " 'tell',\n",
       " 'input',\n",
       " 'checking',\n",
       " 'statistics',\n",
       " 'its',\n",
       " 'mulyiple',\n",
       " 'series',\n",
       " 'each',\n",
       " 'techniques',\n",
       " 'theirs',\n",
       " 'timestamp',\n",
       " 'charge',\n",
       " 'from',\n",
       " 'same',\n",
       " 'then',\n",
       " 'But',\n",
       " 'graphs',\n",
       " 'recorded',\n",
       " 'able',\n",
       " '2020s',\n",
       " 'X_test',\n",
       " 'specifically',\n",
       " 'falls',\n",
       " 'Tho',\n",
       " 'into',\n",
       " 'chg',\n",
       " 'losses',\n",
       " 'under',\n",
       " 'out',\n",
       " 'July',\n",
       " 'matrix',\n",
       " 'column',\n",
       " 'metrics',\n",
       " 'outcomes',\n",
       " 'history.It',\n",
       " 'figure',\n",
       " '58732.365',\n",
       " 'm',\n",
       " 'which',\n",
       " 'when',\n",
       " 'enters',\n",
       " 'Change',\n",
       " 'arte',\n",
       " 'most',\n",
       " 'On',\n",
       " 'Series',\n",
       " 'authentic',\n",
       " 'was',\n",
       " 'columns',\n",
       " 'sir',\n",
       " 'formulas',\n",
       " 'lins',\n",
       " 'how',\n",
       " 'Model',\n",
       " 'other',\n",
       " 'probability',\n",
       " 'second',\n",
       " 'taking',\n",
       " 'varriance.we',\n",
       " 'example',\n",
       " 'areas',\n",
       " 'predicted',\n",
       " 'last',\n",
       " 'feel',\n",
       " 'thus',\n",
       " \"'d\",\n",
       " 'higher',\n",
       " '1980s',\n",
       " 'very',\n",
       " 'change',\n",
       " 'stocks',\n",
       " 'some',\n",
       " 'The',\n",
       " 'wouldnt',\n",
       " 'vector.Used',\n",
       " 'next',\n",
       " 'every',\n",
       " 'has',\n",
       " 'previous',\n",
       " 'history',\n",
       " 'n',\n",
       " 'proper',\n",
       " 'user',\n",
       " 'solve',\n",
       " 'variance',\n",
       " 'function',\n",
       " 'better',\n",
       " '1st',\n",
       " 'population',\n",
       " 'Jun',\n",
       " 'provide',\n",
       " 'depends',\n",
       " 'Trend',\n",
       " 'total',\n",
       " 'growth',\n",
       " 'A2',\n",
       " '2021',\n",
       " 'open',\n",
       " 'linear',\n",
       " 'already',\n",
       " 'maximum',\n",
       " 'different',\n",
       " 'root',\n",
       " 'whether',\n",
       " 'came',\n",
       " 'high',\n",
       " 'work',\n",
       " 'get',\n",
       " 'attributes',\n",
       " 'helps',\n",
       " 'excluding',\n",
       " 'loss',\n",
       " 'comparative',\n",
       " 'eachother/mean',\n",
       " 'have',\n",
       " 'correlated',\n",
       " 'coming',\n",
       " 'model',\n",
       " 'initially',\n",
       " 'capable',\n",
       " 'lack',\n",
       " 'observing',\n",
       " 'my',\n",
       " 'should',\n",
       " 'these',\n",
       " 'nearly',\n",
       " 'etc',\n",
       " 'insights',\n",
       " 'dimensionality',\n",
       " 'point',\n",
       " 'highly',\n",
       " 'improvent',\n",
       " 'while',\n",
       " 'any',\n",
       " 'S-curves',\n",
       " 'predic',\n",
       " '.Also',\n",
       " 'ok',\n",
       " 'understand',\n",
       " 'suggest',\n",
       " 'date',\n",
       " 'increase',\n",
       " 'appropriate',\n",
       " 'reducing',\n",
       " 'little',\n",
       " 'another',\n",
       " 'Eighties',\n",
       " 'calculated',\n",
       " 'and',\n",
       " 'correlation',\n",
       " 'gradually',\n",
       " 'huge',\n",
       " 'investors',\n",
       " 'Gated',\n",
       " 'facts',\n",
       " 'by',\n",
       " 'actually',\n",
       " '2020',\n",
       " 'learning',\n",
       " 'labelled',\n",
       " 'squared',\n",
       " 'recurrent',\n",
       " 'dataset.used',\n",
       " 'It',\n",
       " 'obtained',\n",
       " 'varriance',\n",
       " 'of',\n",
       " 'less',\n",
       " 'Usually',\n",
       " 'long',\n",
       " 'beyond',\n",
       " 'data.then',\n",
       " 'related',\n",
       " 'calculus',\n",
       " 'improve',\n",
       " \"'s\",\n",
       " 'According',\n",
       " 'would',\n",
       " 'Price',\n",
       " 'Monday',\n",
       " 'system',\n",
       " 'So',\n",
       " 'things',\n",
       " 'large',\n",
       " 'predictions',\n",
       " 'predicting',\n",
       " 'above',\n",
       " 'Chg',\n",
       " 'section',\n",
       " 'profit',\n",
       " 'improvement',\n",
       " 'pandas',\n",
       " 'helpfull',\n",
       " 'Suggestions',\n",
       " 'pricing',\n",
       " 'Y_test',\n",
       " 'check',\n",
       " 'sales',\n",
       " 'days',\n",
       " 'almost',\n",
       " 'the',\n",
       " 'will',\n",
       " 'varying',\n",
       " 'predict',\n",
       " 'easier',\n",
       " 'life-cycle',\n",
       " 'sufficient',\n",
       " 'bigger',\n",
       " 'vs',\n",
       " 'data',\n",
       " 'I',\n",
       " 'And',\n",
       " 'eight',\n",
       " 'income',\n",
       " 'considering',\n",
       " 'After',\n",
       " 'find',\n",
       " 'June',\n",
       " '3',\n",
       " 'may',\n",
       " '/improve',\n",
       " 'but',\n",
       " '2',\n",
       " 'nearby',\n",
       " 'undoubtedly',\n",
       " 'gap',\n",
       " 'daily',\n",
       " 's',\n",
       " 'with',\n",
       " 'form',\n",
       " 'that',\n",
       " 'accurate',\n",
       " 'april',\n",
       " 'such',\n",
       " 'changed',\n",
       " 'found',\n",
       " 'Thursday',\n",
       " 'anticipated',\n",
       " '(',\n",
       " 'corner',\n",
       " 'be',\n",
       " 'Pretty',\n",
       " 'evaluate',\n",
       " 'seperated',\n",
       " '<',\n",
       " 'negative',\n",
       " 'occur',\n",
       " 'relate',\n",
       " 'thought',\n",
       " 'median',\n",
       " 'opens',\n",
       " 'new',\n",
       " 'Linear',\n",
       " 'enables',\n",
       " 'sample.so',\n",
       " 'value',\n",
       " 'an',\n",
       " 'percentage',\n",
       " 'our',\n",
       " 'Chg\\U00100ce6ature',\n",
       " 'Friday',\n",
       " 'excessive',\n",
       " 'results',\n",
       " 'help',\n",
       " 'as',\n",
       " 'use',\n",
       " 'supervised',\n",
       " 'does',\n",
       " 'discrete',\n",
       " 'investements',\n",
       " 'time',\n",
       " 'contains',\n",
       " 'future',\n",
       " 'done',\n",
       " 'provided',\n",
       " 'nullable',\n",
       " 'more',\n",
       " 'projections',\n",
       " 'need',\n",
       " 'look',\n",
       " 'To',\n",
       " 'collection',\n",
       " 'being',\n",
       " 'trends',\n",
       " 'case',\n",
       " 'compared',\n",
       " '1698.9526',\n",
       " 'imply',\n",
       " 'situation',\n",
       " 'months',\n",
       " 'rough',\n",
       " \"n't\",\n",
       " 'are',\n",
       " 'obtain',\n",
       " 'kind',\n",
       " 'if',\n",
       " 'easy',\n",
       " 'over',\n",
       " 'Y',\n",
       " 'means',\n",
       " 'nearest',\n",
       " 'pseudo-inverse',\n",
       " 'closes',\n",
       " 'a',\n",
       " 'way',\n",
       " 'quartile',\n",
       " '29',\n",
       " 'Like',\n",
       " '50',\n",
       " 'week',\n",
       " 'those',\n",
       " 'priceafter',\n",
       " 'numpy',\n",
       " 'examine',\n",
       " 'imported',\n",
       " 'there',\n",
       " 'not',\n",
       " 'everyday',\n",
       " 'version',\n",
       " 'technique',\n",
       " 'models',\n",
       " 'analysis',\n",
       " 'to',\n",
       " 'We',\n",
       " 'Wednesday',\n",
       " 'flows',\n",
       " 'information',\n",
       " 'bad',\n",
       " 'normal',\n",
       " 'like',\n",
       " 'apply',\n",
       " 'original',\n",
       " 'for',\n",
       " 'available',\n",
       " 'before',\n",
       " 'test_split_data',\n",
       " 'set.And',\n",
       " 'feature']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "token_population = list(set(chain.from_iterable(df['tokenized_column'])))\n",
    "token_population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927c2dac",
   "metadata": {},
   "source": [
    "#A3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "172fee64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this', 'at', 'am', 'where', 'ain', 'yourself', 'do', 'after', 'so', 'further', 'll', 'through', 'own', \"mustn't\", \"won't\", 'in', 'again', 'he', 'doesn', \"don't\", 'hadn', 'but', \"you'll\", 'is', 'no', 'herself', 'whom', 'shan', 'i', 'it', \"couldn't\", 's', 'ourselves', 'with', 'here', 'mightn', 'that', 'such', \"weren't\", 'myself', 'shouldn', 'now', 'have', 'be', 'once', 're', 'my', 'should', 'these', 'or', \"isn't\", 'can', \"didn't\", 'mustn', 'what', 'while', 'any', 'our', 'an', \"that'll\", 'isn', 'as', 've', 'why', \"shouldn't\", \"doesn't\", 'does', \"needn't\", 'all', 'only', 'they', 'wasn', 'himself', \"hasn't\", 'needn', 'their', 'hers', 'and', 'did', 'hasn', 'its', 'more', 'her', 'doing', 'on', 'having', 'by', 'being', 'each', 'theirs', 'against', \"aren't\", 'haven', 'from', 'wouldn', 'same', 'then', 'we', 'nor', 'couldn', 'down', 'into', \"you'd\", 'him', 'than', 'are', 'both', 'under', \"she's\", 'if', 'because', 'out', 'of', 'up', 'were', \"hadn't\", 'over', 'ma', 'itself', 'aren', 't', 'y', 'ours', 'me', 'm', 'a', 'yours', 'which', 'who', 'when', \"shan't\", 'been', \"wasn't\", 'most', 'your', \"haven't\", 'them', 'about', 'was', \"it's\", 'how', \"mightn't\", 'those', 'other', 'don', \"wouldn't\", 'o', \"you're\", 'she', 'there', 'his', 'below', 'you', 'not', 'during', \"should've\", 'above', 'too', 'had', 'until', 'few', 'to', 'didn', \"you've\", 'themselves', 'very', 'won', 'the', 'yourselves', 'off', 'will', 'between', 'some', 'weren', 'just', 'for', 'd', 'before', 'has'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dines\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Get the list of English stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Print or use the stop words as needed\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b05d703",
   "metadata": {},
   "source": [
    "#A4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6059161a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bag-of-Words Representation for Token Population:\n",
      "   124  1550  1560  16  1698  1980s  1st  2020  2020s  2021  ...  without  \\\n",
      "0    1     1     1   1     1      1    1     1      1     1  ...        1   \n",
      "\n",
      "   work  would  wouldnt  x_test  x_train  y_test  y_train  year  years  \n",
      "0     1      1        1       1        1       1        1     1      1  \n",
      "\n",
      "[1 rows x 423 columns]\n"
     ]
    }
   ],
   "source": [
    "# Remove stop words from the token population\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "filtered_token_population = [token for token in token_population if token not in stop_words]\n",
    "\n",
    "# Create a bag-of-words representation for the filtered token population\n",
    "vectorizer = CountVectorizer()\n",
    "bag_of_words = vectorizer.fit_transform([' '.join(filtered_token_population)])\n",
    "\n",
    "# Convert the bag-of-words representation to a DataFrame\n",
    "bow_df = pd.DataFrame(bag_of_words.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Display the result\n",
    "print(\"\\nBag-of-Words Representation for Token Population:\")\n",
    "print(bow_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e0f6e0",
   "metadata": {},
   "source": [
    "#A5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7216565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student</th>\n",
       "      <th>Report</th>\n",
       "      <th>tokenized_column</th>\n",
       "      <th>tokens_low</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1</td>\n",
       "      <td>So based on the data, the first point what can...</td>\n",
       "      <td>[So, based, on, the, data, ,, the, first, poin...</td>\n",
       "      <td>[so, based, on, the, data, ,, the, first, poin...</td>\n",
       "      <td>[0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 0, 0, 7, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S2</td>\n",
       "      <td>I would suggest to make an application in whic...</td>\n",
       "      <td>[I, would, suggest, to, make, an, application,...</td>\n",
       "      <td>[i, would, suggest, to, make, an, application,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S3</td>\n",
       "      <td>so what i observed is features in irctc data a...</td>\n",
       "      <td>[so, what, i, observed, is, features, in, irct...</td>\n",
       "      <td>[so, what, i, observed, is, features, in, irct...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 7, 0, 0, 2, 1, 0, 0, 1, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S4</td>\n",
       "      <td>This can be solved with a Regression Machine L...</td>\n",
       "      <td>[This, can, be, solved, with, a, Regression, M...</td>\n",
       "      <td>[this, can, be, solved, with, a, regression, m...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S5</td>\n",
       "      <td>From the stock data provided to build a system...</td>\n",
       "      <td>[From, the, stock, data, provided, to, build, ...</td>\n",
       "      <td>[from, the, stock, data, provided, to, build, ...</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>S6</td>\n",
       "      <td>IRCTC Stock Price \\nSo what i found is functio...</td>\n",
       "      <td>[IRCTC, Stock, Price, So, what, i, found, is, ...</td>\n",
       "      <td>[irctc, stock, price, so, what, i, found, is, ...</td>\n",
       "      <td>[0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 1, 7, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S7</td>\n",
       "      <td>The loss probability is showing close to 50 , ...</td>\n",
       "      <td>[The, loss, probability, is, showing, close, t...</td>\n",
       "      <td>[the, loss, probability, is, showing, close, t...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S8</td>\n",
       "      <td>1.In the first problem we were able to find ou...</td>\n",
       "      <td>[1.In, the, first, problem, we, were, able, to...</td>\n",
       "      <td>[1.in, the, first, problem, we, were, able, to...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S9</td>\n",
       "      <td>okay so basically using numpy,we could solve t...</td>\n",
       "      <td>[okay, so, basically, using, numpy, ,, we, cou...</td>\n",
       "      <td>[okay, so, basically, using, numpy, ,, we, cou...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S10</td>\n",
       "      <td>Machine learning enables us to build a system ...</td>\n",
       "      <td>[Machine, learning, enables, us, to, build, a,...</td>\n",
       "      <td>[machine, learning, enables, us, to, build, a,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>S11</td>\n",
       "      <td>From the stock,I see that almost all the value...</td>\n",
       "      <td>[From, the, stock, ,, I, see, that, almost, al...</td>\n",
       "      <td>[from, the, stock, ,, i, see, that, almost, al...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>S12</td>\n",
       "      <td>The loss probability is showing close to 50 , ...</td>\n",
       "      <td>[The, loss, probability, is, showing, close, t...</td>\n",
       "      <td>[the, loss, probability, is, showing, close, t...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>S13</td>\n",
       "      <td>After observing the daily trend of change perc...</td>\n",
       "      <td>[After, observing, the, daily, trend, of, chan...</td>\n",
       "      <td>[after, observing, the, daily, trend, of, chan...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>S14</td>\n",
       "      <td>Machine learning helps us to build a system th...</td>\n",
       "      <td>[Machine, learning, helps, us, to, build, a, s...</td>\n",
       "      <td>[machine, learning, helps, us, to, build, a, s...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>S15</td>\n",
       "      <td>I have observed that, the values are closely r...</td>\n",
       "      <td>[I, have, observed, that, ,, the, values, are,...</td>\n",
       "      <td>[i, have, observed, that, ,, the, values, are,...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>S16</td>\n",
       "      <td>To build a system that is capable of predictin...</td>\n",
       "      <td>[To, build, a, system, that, is, capable, of, ...</td>\n",
       "      <td>[to, build, a, system, that, is, capable, of, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>S17</td>\n",
       "      <td>We are given Price and Change  for every month...</td>\n",
       "      <td>[We, are, given, Price, and, Change, for, ever...</td>\n",
       "      <td>[we, are, given, price, and, change, for, ever...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>S18</td>\n",
       "      <td>Usually its difficult to predict stock prices ...</td>\n",
       "      <td>[Usually, its, difficult, to, predict, stock, ...</td>\n",
       "      <td>[usually, its, difficult, to, predict, stock, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>S19</td>\n",
       "      <td>sry sir, i dont know how to suggest a sytem or...</td>\n",
       "      <td>[sry, sir, ,, i, dont, know, how, to, suggest,...</td>\n",
       "      <td>[sry, sir, ,, i, dont, know, how, to, suggest,...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>S20</td>\n",
       "      <td>\\nSuggestions to build a system that may be ab...</td>\n",
       "      <td>[Suggestions, to, build, a, system, that, may,...</td>\n",
       "      <td>[suggestions, to, build, a, system, that, may,...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>S21</td>\n",
       "      <td>After Analysing, irctc stocks I thought it’s b...</td>\n",
       "      <td>[After, Analysing, ,, irctc, stocks, I, though...</td>\n",
       "      <td>[after, analysing, ,, irctc, stocks, i, though...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>S22</td>\n",
       "      <td>we can apply REGRESSION</td>\n",
       "      <td>[we, can, apply, REGRESSION]</td>\n",
       "      <td>[we, can, apply, regression]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>S23</td>\n",
       "      <td>So for that first I imported the dataset and t...</td>\n",
       "      <td>[So, for, that, first, I, imported, the, datas...</td>\n",
       "      <td>[so, for, that, first, i, imported, the, datas...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 3, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>S24</td>\n",
       "      <td>So for that first I imported the dataset and t...</td>\n",
       "      <td>[So, for, that, first, I, imported, the, datas...</td>\n",
       "      <td>[so, for, that, first, i, imported, the, datas...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 3, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>S25</td>\n",
       "      <td>From the stock I see that almost all the value...</td>\n",
       "      <td>[From, the, stock, I, see, that, almost, all, ...</td>\n",
       "      <td>[from, the, stock, i, see, that, almost, all, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>S26</td>\n",
       "      <td>i observed that the features in irctc data ar...</td>\n",
       "      <td>[i, observed, that, the, features, in, irctc, ...</td>\n",
       "      <td>[i, observed, that, the, features, in, irctc, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>S27</td>\n",
       "      <td>A1  \\nI have solved the problems and I found t...</td>\n",
       "      <td>[A1, I, have, solved, the, problems, and, I, f...</td>\n",
       "      <td>[a1, i, have, solved, the, problems, and, i, f...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>S28</td>\n",
       "      <td>“IRCTC Stock Price  \\n\\nso what i observed is ...</td>\n",
       "      <td>[“, IRCTC, Stock, Price, so, what, i, observed...</td>\n",
       "      <td>[“, irctc, stock, price, so, what, i, observed...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 7, 0, 0, 2, 1, 0, 0, 1, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>S29</td>\n",
       "      <td>IRCTC Stock Price \\nSo what i found is functio...</td>\n",
       "      <td>[IRCTC, Stock, Price, So, what, i, found, is, ...</td>\n",
       "      <td>[irctc, stock, price, so, what, i, found, is, ...</td>\n",
       "      <td>[0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 1, 7, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>S30</td>\n",
       "      <td>From the stock data set, I realized that most ...</td>\n",
       "      <td>[From, the, stock, data, set, ,, I, realized, ...</td>\n",
       "      <td>[from, the, stock, data, set, ,, i, realized, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>S31</td>\n",
       "      <td>The loss probability is showing close to 50 , ...</td>\n",
       "      <td>[The, loss, probability, is, showing, close, t...</td>\n",
       "      <td>[the, loss, probability, is, showing, close, t...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>S32</td>\n",
       "      <td>From the above information I understand that v...</td>\n",
       "      <td>[From, the, above, information, I, understand,...</td>\n",
       "      <td>[from, the, above, information, i, understand,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>S33</td>\n",
       "      <td>From the stock I see that almost all the valu...</td>\n",
       "      <td>[From, the, stock, I, see, that, almost, all, ...</td>\n",
       "      <td>[from, the, stock, i, see, that, almost, all, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>S34</td>\n",
       "      <td>IRCTC Stock Price \\nso, what I observed is fea...</td>\n",
       "      <td>[IRCTC, Stock, Price, so, ,, what, I, observed...</td>\n",
       "      <td>[irctc, stock, price, so, ,, what, i, observed...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 12, 0, 0, 2, 1, 0, 0, 1, 0, 0, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>S35</td>\n",
       "      <td>The loss probability is showing close to 50 , ...</td>\n",
       "      <td>[The, loss, probability, is, showing, close, t...</td>\n",
       "      <td>[the, loss, probability, is, showing, close, t...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>S36</td>\n",
       "      <td>we can apply REGRESSION</td>\n",
       "      <td>[we, can, apply, REGRESSION]</td>\n",
       "      <td>[we, can, apply, regression]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>S37</td>\n",
       "      <td>“IRCTC Stock Price  \\nso what i observed is fe...</td>\n",
       "      <td>[“, IRCTC, Stock, Price, so, what, i, observed...</td>\n",
       "      <td>[“, irctc, stock, price, so, what, i, observed...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 5, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Student                                             Report  \\\n",
       "0       S1  So based on the data, the first point what can...   \n",
       "1       S2  I would suggest to make an application in whic...   \n",
       "2       S3  so what i observed is features in irctc data a...   \n",
       "3       S4  This can be solved with a Regression Machine L...   \n",
       "4       S5  From the stock data provided to build a system...   \n",
       "5       S6  IRCTC Stock Price \\nSo what i found is functio...   \n",
       "6       S7  The loss probability is showing close to 50 , ...   \n",
       "7       S8  1.In the first problem we were able to find ou...   \n",
       "8       S9  okay so basically using numpy,we could solve t...   \n",
       "9      S10  Machine learning enables us to build a system ...   \n",
       "10     S11  From the stock,I see that almost all the value...   \n",
       "11     S12  The loss probability is showing close to 50 , ...   \n",
       "12     S13  After observing the daily trend of change perc...   \n",
       "13     S14  Machine learning helps us to build a system th...   \n",
       "14     S15  I have observed that, the values are closely r...   \n",
       "15     S16  To build a system that is capable of predictin...   \n",
       "16     S17  We are given Price and Change  for every month...   \n",
       "17     S18  Usually its difficult to predict stock prices ...   \n",
       "18     S19  sry sir, i dont know how to suggest a sytem or...   \n",
       "19     S20  \\nSuggestions to build a system that may be ab...   \n",
       "20     S21  After Analysing, irctc stocks I thought it’s b...   \n",
       "21     S22                            we can apply REGRESSION   \n",
       "22     S23  So for that first I imported the dataset and t...   \n",
       "23     S24  So for that first I imported the dataset and t...   \n",
       "24     S25  From the stock I see that almost all the value...   \n",
       "25     S26   i observed that the features in irctc data ar...   \n",
       "26     S27  A1  \\nI have solved the problems and I found t...   \n",
       "27     S28  “IRCTC Stock Price  \\n\\nso what i observed is ...   \n",
       "28     S29  IRCTC Stock Price \\nSo what i found is functio...   \n",
       "29     S30  From the stock data set, I realized that most ...   \n",
       "30     S31  The loss probability is showing close to 50 , ...   \n",
       "31     S32  From the above information I understand that v...   \n",
       "32     S33   From the stock I see that almost all the valu...   \n",
       "33     S34  IRCTC Stock Price \\nso, what I observed is fea...   \n",
       "34     S35  The loss probability is showing close to 50 , ...   \n",
       "35     S36                            we can apply REGRESSION   \n",
       "36     S37  “IRCTC Stock Price  \\nso what i observed is fe...   \n",
       "\n",
       "                                     tokenized_column  \\\n",
       "0   [So, based, on, the, data, ,, the, first, poin...   \n",
       "1   [I, would, suggest, to, make, an, application,...   \n",
       "2   [so, what, i, observed, is, features, in, irct...   \n",
       "3   [This, can, be, solved, with, a, Regression, M...   \n",
       "4   [From, the, stock, data, provided, to, build, ...   \n",
       "5   [IRCTC, Stock, Price, So, what, i, found, is, ...   \n",
       "6   [The, loss, probability, is, showing, close, t...   \n",
       "7   [1.In, the, first, problem, we, were, able, to...   \n",
       "8   [okay, so, basically, using, numpy, ,, we, cou...   \n",
       "9   [Machine, learning, enables, us, to, build, a,...   \n",
       "10  [From, the, stock, ,, I, see, that, almost, al...   \n",
       "11  [The, loss, probability, is, showing, close, t...   \n",
       "12  [After, observing, the, daily, trend, of, chan...   \n",
       "13  [Machine, learning, helps, us, to, build, a, s...   \n",
       "14  [I, have, observed, that, ,, the, values, are,...   \n",
       "15  [To, build, a, system, that, is, capable, of, ...   \n",
       "16  [We, are, given, Price, and, Change, for, ever...   \n",
       "17  [Usually, its, difficult, to, predict, stock, ...   \n",
       "18  [sry, sir, ,, i, dont, know, how, to, suggest,...   \n",
       "19  [Suggestions, to, build, a, system, that, may,...   \n",
       "20  [After, Analysing, ,, irctc, stocks, I, though...   \n",
       "21                       [we, can, apply, REGRESSION]   \n",
       "22  [So, for, that, first, I, imported, the, datas...   \n",
       "23  [So, for, that, first, I, imported, the, datas...   \n",
       "24  [From, the, stock, I, see, that, almost, all, ...   \n",
       "25  [i, observed, that, the, features, in, irctc, ...   \n",
       "26  [A1, I, have, solved, the, problems, and, I, f...   \n",
       "27  [“, IRCTC, Stock, Price, so, what, i, observed...   \n",
       "28  [IRCTC, Stock, Price, So, what, i, found, is, ...   \n",
       "29  [From, the, stock, data, set, ,, I, realized, ...   \n",
       "30  [The, loss, probability, is, showing, close, t...   \n",
       "31  [From, the, above, information, I, understand,...   \n",
       "32  [From, the, stock, I, see, that, almost, all, ...   \n",
       "33  [IRCTC, Stock, Price, so, ,, what, I, observed...   \n",
       "34  [The, loss, probability, is, showing, close, t...   \n",
       "35                       [we, can, apply, REGRESSION]   \n",
       "36  [“, IRCTC, Stock, Price, so, what, i, observed...   \n",
       "\n",
       "                                           tokens_low  \\\n",
       "0   [so, based, on, the, data, ,, the, first, poin...   \n",
       "1   [i, would, suggest, to, make, an, application,...   \n",
       "2   [so, what, i, observed, is, features, in, irct...   \n",
       "3   [this, can, be, solved, with, a, regression, m...   \n",
       "4   [from, the, stock, data, provided, to, build, ...   \n",
       "5   [irctc, stock, price, so, what, i, found, is, ...   \n",
       "6   [the, loss, probability, is, showing, close, t...   \n",
       "7   [1.in, the, first, problem, we, were, able, to...   \n",
       "8   [okay, so, basically, using, numpy, ,, we, cou...   \n",
       "9   [machine, learning, enables, us, to, build, a,...   \n",
       "10  [from, the, stock, ,, i, see, that, almost, al...   \n",
       "11  [the, loss, probability, is, showing, close, t...   \n",
       "12  [after, observing, the, daily, trend, of, chan...   \n",
       "13  [machine, learning, helps, us, to, build, a, s...   \n",
       "14  [i, have, observed, that, ,, the, values, are,...   \n",
       "15  [to, build, a, system, that, is, capable, of, ...   \n",
       "16  [we, are, given, price, and, change, for, ever...   \n",
       "17  [usually, its, difficult, to, predict, stock, ...   \n",
       "18  [sry, sir, ,, i, dont, know, how, to, suggest,...   \n",
       "19  [suggestions, to, build, a, system, that, may,...   \n",
       "20  [after, analysing, ,, irctc, stocks, i, though...   \n",
       "21                       [we, can, apply, regression]   \n",
       "22  [so, for, that, first, i, imported, the, datas...   \n",
       "23  [so, for, that, first, i, imported, the, datas...   \n",
       "24  [from, the, stock, i, see, that, almost, all, ...   \n",
       "25  [i, observed, that, the, features, in, irctc, ...   \n",
       "26  [a1, i, have, solved, the, problems, and, i, f...   \n",
       "27  [“, irctc, stock, price, so, what, i, observed...   \n",
       "28  [irctc, stock, price, so, what, i, found, is, ...   \n",
       "29  [from, the, stock, data, set, ,, i, realized, ...   \n",
       "30  [the, loss, probability, is, showing, close, t...   \n",
       "31  [from, the, above, information, i, understand,...   \n",
       "32  [from, the, stock, i, see, that, almost, all, ...   \n",
       "33  [irctc, stock, price, so, ,, what, i, observed...   \n",
       "34  [the, loss, probability, is, showing, close, t...   \n",
       "35                       [we, can, apply, regression]   \n",
       "36  [“, irctc, stock, price, so, what, i, observed...   \n",
       "\n",
       "                                                   V1  \\\n",
       "0   [0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2   [0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, ...   \n",
       "3   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4   [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...   \n",
       "5   [0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, ...   \n",
       "6   [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...   \n",
       "7   [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "8   [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "9   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "10  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...   \n",
       "11  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...   \n",
       "12  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "13  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "14  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "15  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "16  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "17  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...   \n",
       "18  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "19  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "20  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "21  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "22  [0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "23  [0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "24  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...   \n",
       "25  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, ...   \n",
       "26  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...   \n",
       "27  [0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, ...   \n",
       "28  [0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, ...   \n",
       "29  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...   \n",
       "30  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...   \n",
       "31  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "32  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...   \n",
       "33  [0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, ...   \n",
       "34  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...   \n",
       "35  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "36  [0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, ...   \n",
       "\n",
       "                                                   V2  \n",
       "0   [0, 1, 0, 0, 7, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2   [0, 0, 0, 0, 7, 0, 0, 2, 1, 0, 0, 1, 0, 0, 1, ...  \n",
       "3   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4   [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...  \n",
       "5   [0, 0, 0, 1, 7, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, ...  \n",
       "6   [0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...  \n",
       "7   [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "8   [0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "10  [0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...  \n",
       "11  [0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...  \n",
       "12  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "13  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "14  [0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "15  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "16  [0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "17  [0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...  \n",
       "18  [0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "19  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "20  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "21  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "22  [0, 0, 0, 0, 3, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "23  [0, 0, 0, 0, 3, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "24  [0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...  \n",
       "25  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, ...  \n",
       "26  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...  \n",
       "27  [0, 0, 0, 0, 7, 0, 0, 2, 1, 0, 0, 1, 0, 0, 1, ...  \n",
       "28  [0, 0, 0, 1, 7, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, ...  \n",
       "29  [0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...  \n",
       "30  [0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...  \n",
       "31  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "32  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...  \n",
       "33  [0, 0, 0, 0, 12, 0, 0, 2, 1, 0, 0, 1, 0, 0, 1,...  \n",
       "34  [0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...  \n",
       "35  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "36  [0, 0, 0, 0, 5, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['tokens_low'] = df['tokenized_column'].apply(lambda x: [item.lower() for item in x])\n",
    "\n",
    "df['V1']=None\n",
    "df['V2']=None\n",
    "\n",
    "for i in range(len(df['tokens_low'])):\n",
    "    c=[]\n",
    "    for j in filtered_token_population:\n",
    "        if j in df['tokens_low'][i]:\n",
    "            c.append(1)\n",
    "        else:\n",
    "            c.append(0)\n",
    "    df.at[i,'V1']=c\n",
    "\n",
    "for i in range(len(df['tokens_low'])):\n",
    "    f=[]\n",
    "    for j in filtered_token_population:\n",
    "        e=0\n",
    "        for k in range(len(df['tokens_low'][i])):\n",
    "            if j == df['tokens_low'][i][k]:\n",
    "                e+=1\n",
    "        f.append(e)\n",
    "    df.at[i,'V2']=f\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26a6e1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e05a9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Matrix:\n",
      "          0         1         2         3         4         5         6   \\\n",
      "0   1.000000  0.197789  0.423400  0.235702  0.308767  0.385481  0.414039   \n",
      "1   0.197789  1.000000  0.152570  0.129099  0.272772  0.076499  0.157485   \n",
      "2   0.423400  0.152570  1.000000  0.165452  0.149820  0.672272  0.438261   \n",
      "3   0.235702  0.129099  0.165452  1.000000  0.295804  0.071107  0.390360   \n",
      "4   0.308767  0.272772  0.149820  0.295804  1.000000  0.110176  0.309295   \n",
      "5   0.385481  0.076499  0.672272  0.071107  0.110176  1.000000  0.300704   \n",
      "6   0.414039  0.157485  0.438261  0.390360  0.309295  0.300704  1.000000   \n",
      "7   0.239395  0.093659  0.154326  0.145095  0.168613  0.120368  0.212398   \n",
      "8   0.433861  0.115517  0.350474  0.153393  0.216068  0.296921  0.349291   \n",
      "9   0.342580  0.324760  0.079277  0.223607  0.354342  0.079500  0.109109   \n",
      "10  0.348337  0.153864  0.371844  0.095346  0.181310  0.338988  0.325669   \n",
      "11  0.414039  0.157485  0.438261  0.390360  0.309295  0.300704  1.000000   \n",
      "12  0.212132  0.161374  0.165452  0.100000  0.190160  0.082958  0.170783   \n",
      "13  0.228315  0.297746  0.043610  0.138380  0.389841  0.043732  0.045015   \n",
      "14  0.404520  0.153864  0.371844  0.143019  0.201456  0.338988  0.348932   \n",
      "15  0.319505  0.291667  0.213597  0.129099  0.409159  0.152998  0.220479   \n",
      "16  0.611111  0.273861  0.412258  0.188562  0.358569  0.379894  0.437042   \n",
      "17  0.439205  0.216506  0.264258  0.111803  0.377964  0.256166  0.272772   \n",
      "18  0.387585  0.244949  0.328871  0.189737  0.293987  0.254841  0.493771   \n",
      "19  0.223917  0.290474  0.189088  0.100000  0.359191  0.154065  0.146385   \n",
      "20  0.360255  0.136083  0.249145  0.210819  0.155902  0.337289  0.231455   \n",
      "21  0.105409  0.000000  0.052852  0.223607  0.000000  0.053000  0.000000   \n",
      "22  0.360281  0.157867  0.368512  0.305709  0.361720  0.275348  0.343093   \n",
      "23  0.360281  0.157867  0.368512  0.305709  0.361720  0.275348  0.343093   \n",
      "24  0.345033  0.188982  0.322929  0.146385  0.206197  0.277573  0.309524   \n",
      "25  0.233333  0.182574  0.451255  0.141421  0.119523  0.251401  0.172516   \n",
      "26  0.294528  0.246461  0.237921  0.242974  0.249354  0.205679  0.287929   \n",
      "27  0.441497  0.164197  0.989307  0.161874  0.166125  0.679659  0.428784   \n",
      "28  0.386568  0.076715  0.668550  0.071307  0.110487  0.997187  0.301552   \n",
      "29  0.352872  0.212132  0.422901  0.292119  0.231455  0.285610  0.391983   \n",
      "30  0.414039  0.157485  0.438261  0.390360  0.309295  0.300704  1.000000   \n",
      "31  0.242593  0.159448  0.184885  0.164677  0.173972  0.078065  0.120532   \n",
      "32  0.318341  0.189525  0.249831  0.117444  0.173702  0.208777  0.257881   \n",
      "33  0.575686  0.176483  0.943484  0.182271  0.238773  0.699877  0.524740   \n",
      "34  0.414039  0.157485  0.438261  0.390360  0.309295  0.300704  1.000000   \n",
      "35  0.105409  0.000000  0.052852  0.223607  0.000000  0.053000  0.000000   \n",
      "36  0.464864  0.209274  0.715206  0.189120  0.216920  0.544313  0.382308   \n",
      "\n",
      "          7         8         9   ...        27        28        29        30  \\\n",
      "0   0.239395  0.433861  0.342580  ...  0.441497  0.386568  0.352872  0.414039   \n",
      "1   0.093659  0.115517  0.324760  ...  0.164197  0.076715  0.212132  0.157485   \n",
      "2   0.154326  0.350474  0.079277  ...  0.989307  0.668550  0.422901  0.438261   \n",
      "3   0.145095  0.153393  0.223607  ...  0.161874  0.071307  0.292119  0.390360   \n",
      "4   0.168613  0.216068  0.354342  ...  0.166125  0.110487  0.231455  0.309295   \n",
      "5   0.120368  0.296921  0.079500  ...  0.679659  0.997187  0.285610  0.300704   \n",
      "6   0.212398  0.349291  0.109109  ...  0.428784  0.301552  0.391983  1.000000   \n",
      "7   1.000000  0.296755  0.121666  ...  0.150989  0.120708  0.264906  0.212398   \n",
      "8   0.296755  1.000000  0.142915  ...  0.342895  0.297758  0.364073  0.349291   \n",
      "9   0.121666  0.142915  1.000000  ...  0.103418  0.079724  0.122474  0.109109   \n",
      "10  0.155636  0.341260  0.106600  ...  0.374828  0.328613  0.365563  0.325669   \n",
      "11  0.212398  0.349291  0.109109  ...  0.428784  0.301552  0.391983  1.000000   \n",
      "12  0.108821  0.191741  0.167705  ...  0.161874  0.083192  0.182574  0.170783   \n",
      "13  0.100391  0.058962  0.850923  ...  0.064000  0.043856  0.050529  0.045015   \n",
      "14  0.207514  0.402200  0.159901  ...  0.363803  0.328613  0.382971  0.348932   \n",
      "15  0.117073  0.181527  0.433013  ...  0.223906  0.153429  0.235702  0.220479   \n",
      "16  0.205196  0.397706  0.395285  ...  0.425145  0.380966  0.327052  0.437042   \n",
      "17  0.175740  0.381108  0.291667  ...  0.284398  0.256889  0.326599  0.272772   \n",
      "18  0.137649  0.258705  0.176777  ...  0.336385  0.255560  0.277128  0.493771   \n",
      "19  0.126958  0.089479  0.307459  ...  0.196561  0.154499  0.200832  0.146385   \n",
      "20  0.191180  0.350329  0.206239  ...  0.268133  0.325713  0.288675  0.231455   \n",
      "21  0.000000  0.000000  0.125000  ...  0.051709  0.053149  0.000000  0.000000   \n",
      "22  0.099803  0.140681  0.170896  ...  0.381752  0.276125  0.189769  0.343093   \n",
      "23  0.099803  0.140681  0.170896  ...  0.381752  0.276125  0.189769  0.343093   \n",
      "24  0.194698  0.349291  0.163663  ...  0.327230  0.266757  0.391983  0.309524   \n",
      "25  0.128247  0.108465  0.158114  ...  0.474201  0.252110  0.284019  0.172516   \n",
      "26  0.453270  0.354957  0.232845  ...  0.240803  0.206260  0.329537  0.287929   \n",
      "27  0.150989  0.342895  0.103418  ...  1.000000  0.676079  0.422200  0.428784   \n",
      "28  0.120708  0.297758  0.079724  ...  0.676079  1.000000  0.277736  0.301552   \n",
      "29  0.264906  0.364073  0.122474  ...  0.422200  0.277736  1.000000  0.391983   \n",
      "30  0.212398  0.349291  0.109109  ...  0.428784  0.301552  0.391983  1.000000   \n",
      "31  0.089602  0.157877  0.161101  ...  0.190407  0.068499  0.300658  0.120532   \n",
      "32  0.213007  0.345289  0.196960  ...  0.258008  0.209366  0.321634  0.257881   \n",
      "33  0.211573  0.456664  0.152839  ...  0.944156  0.697519  0.465891  0.524740   \n",
      "34  0.212398  0.349291  0.109109  ...  0.428784  0.301552  0.391983  1.000000   \n",
      "35  0.000000  0.000000  0.125000  ...  0.051709  0.053149  0.000000  0.000000   \n",
      "36  0.196003  0.414424  0.211443  ...  0.743474  0.533005  0.414341  0.382308   \n",
      "\n",
      "          31        32        33        34        35        36  \n",
      "0   0.242593  0.318341  0.575686  0.414039  0.105409  0.464864  \n",
      "1   0.159448  0.189525  0.176483  0.157485  0.000000  0.209274  \n",
      "2   0.184885  0.249831  0.943484  0.438261  0.052852  0.715206  \n",
      "3   0.164677  0.117444  0.182271  0.390360  0.223607  0.189120  \n",
      "4   0.173972  0.173702  0.238773  0.309295  0.000000  0.216920  \n",
      "5   0.078065  0.208777  0.699877  0.300704  0.053000  0.544313  \n",
      "6   0.120532  0.257881  0.524740  1.000000  0.000000  0.382308  \n",
      "7   0.089602  0.213007  0.211573  0.212398  0.000000  0.196003  \n",
      "8   0.157877  0.345289  0.456664  0.349291  0.000000  0.414424  \n",
      "9   0.161101  0.196960  0.152839  0.109109  0.125000  0.211443  \n",
      "10  0.137387  0.783850  0.451849  0.325669  0.000000  0.695516  \n",
      "11  0.120532  0.257881  0.524740  1.000000  0.000000  0.382308  \n",
      "12  0.102923  0.146805  0.182271  0.170783  0.000000  0.162103  \n",
      "13  0.151920  0.108346  0.092483  0.045015  0.103142  0.124621  \n",
      "14  0.157014  0.727860  0.469228  0.348932  0.000000  0.669756  \n",
      "15  0.265747  0.151620  0.282372  0.220479  0.144338  0.226714  \n",
      "16  0.174667  0.276818  0.567093  0.437042  0.210819  0.445760  \n",
      "17  0.153429  0.306382  0.400777  0.272772  0.000000  0.362473  \n",
      "18  0.130189  0.148556  0.426529  0.493771  0.000000  0.307569  \n",
      "19  0.185262  0.058722  0.209611  0.146385  0.335410  0.148594  \n",
      "20  0.151887  0.278543  0.345834  0.231455  0.117851  0.427179  \n",
      "21  0.092057  0.000000  0.040757  0.000000  1.000000  0.060412  \n",
      "22  0.226545  0.107711  0.401197  0.343093  0.136717  0.289079  \n",
      "23  0.226545  0.107711  0.401197  0.343093  0.136717  0.289079  \n",
      "24  0.180797  0.888256  0.400225  0.309524  0.000000  0.751432  \n",
      "25  0.232889  0.166091  0.412431  0.172516  0.000000  0.401184  \n",
      "26  0.142901  0.244593  0.297355  0.287929  0.000000  0.281334  \n",
      "27  0.190407  0.258008  0.944156  0.428784  0.051709  0.743474  \n",
      "28  0.068499  0.209366  0.697519  0.301552  0.053149  0.533005  \n",
      "29  0.300658  0.321634  0.465891  0.391983  0.000000  0.414341  \n",
      "30  0.120532  0.257881  0.524740  1.000000  0.000000  0.382308  \n",
      "31  1.000000  0.169228  0.180095  0.120532  0.092057  0.211333  \n",
      "32  0.169228  1.000000  0.321099  0.257881  0.000000  0.650466  \n",
      "33  0.180095  0.321099  1.000000  0.524740  0.040757  0.743590  \n",
      "34  0.120532  0.257881  0.524740  1.000000  0.000000  0.382308  \n",
      "35  0.092057  0.000000  0.040757  0.000000  1.000000  0.060412  \n",
      "36  0.211333  0.650466  0.743590  0.382308  0.060412  1.000000  \n",
      "\n",
      "[37 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Convert the 'V2' feature vectors to a NumPy array\n",
    "feature_vectors = np.array(list(df['V2']))\n",
    "\n",
    "# Calculate the cosine similarity matrix\n",
    "cosine_sim_matrix = cosine_similarity(feature_vectors)\n",
    "\n",
    "# Create a DataFrame to display the cosine similarity matrix\n",
    "cosine_sim_df = pd.DataFrame(cosine_sim_matrix, index=df.index, columns=df.index)\n",
    "\n",
    "# Display the cosine similarity matrix\n",
    "print(\"Cosine Similarity Matrix:\")\n",
    "print(cosine_sim_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8405fc51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec7d15c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
